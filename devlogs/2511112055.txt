================================================================================
DEVLOG: Phase 3 - Face Detection in Videos
================================================================================
Date: 2025-11-11 20:55
Session: Phase 3 implementation
Status: Complete, ready for testing with FEATURE_FACE_DETECTION=true

================================================================================
OVERVIEW
================================================================================

Implemented face detection in video processing pipeline:
- Detect faces in scene frames using YuNet
- Match faces against enrolled FaceProfile embeddings
- Create ScenePerson associations for matches
- Populate sidecar people array with detected person info

Feature flag: FEATURE_FACE_DETECTION (default: false)
Works with: FEATURE_FACE_ENROLLMENT (Phase 1)

================================================================================
FILES MODIFIED
================================================================================

worker/tasks/video_processor.py:
- Added YuNet model loading to get_model() (lines 73-95)
- Added detect_and_match_faces() function (lines 100-186)
- Integrated face detection into scene processing loop (lines 275-335)
- Added ScenePerson creation after scene commit (lines 343-365)
- Modified sidecar generation to include people (lines 380-418)
- Updated build_sidecar() signature to accept people parameter (line 661)

================================================================================
IMPLEMENTATION DETAILS
================================================================================

1. YuNet Face Detector Loading (lines 73-95):
```python
elif model_name == "yunet":
    yunet_path = "/app/models/.cache/face_detection_yunet_2023mar.onnx"
    if not os.path.exists(yunet_path):
        url = "https://github.com/opencv/opencv_zoo/.../face_detection_yunet_2023mar.onnx"
        urllib.request.urlretrieve(url, yunet_path)

    _models["yunet"] = cv2.FaceDetectorYN.create(
        model=yunet_path,
        input_size=(320, 320),
        score_threshold=0.6,
        nms_threshold=0.3,
    )
```

2. Face Detection & Matching (lines 100-186):
```python
def detect_and_match_faces(image: Image.Image, enrolled_profiles: List[Dict]) -> List[Dict]:
    # Check feature flag
    if not FEATURE_FACE_DETECTION or not enrolled_profiles:
        return []

    # Convert PIL Image to OpenCV format
    # Detect faces with YuNet
    # For each detected face:
    #   - Extract face crop
    #   - Generate embedding (placeholder)
    #   - Compare with enrolled profiles using cosine similarity
    #   - If similarity >= threshold, add to matches

    return matched_people  # [{person_id, name, confidence}, ...]
```

3. Pipeline Integration (lines 275-335):

Step 4.5: Load enrolled profiles for user
```python
enrolled_profiles = []
if FEATURE_FACE_DETECTION:
    profiles = session.query(FaceProfile).filter(
        FaceProfile.user_id == video.user_id,
        FaceProfile.adaface_vec.isnot(None)
    ).all()
    enrolled_profiles = [{person_id, name, embedding}, ...]
```

Step 5-6: Detect faces during scene processing
```python
scene_people_map = {}  # scene_idx -> detected_people

for i, (start_s, end_s) in enumerate(scene_timestamps):
    # ... generate embeddings ...
    frame = extract_frame(video_path, mid_time)

    # Detect faces in frame
    detected_people = detect_and_match_faces(frame, enrolled_profiles)

    # Create scene record
    scene = Scene(...)
    session.add(scene)

    # Store for later ScenePerson creation
    if detected_people:
        scene_people_map[i] = detected_people
```

4. ScenePerson Creation (lines 343-365):
```python
if scene_people_map:
    for scene_idx, detected_people in scene_people_map.items():
        scene = scenes[scene_idx]

        for person in detected_people:
            scene_person = ScenePerson(
                scene_id=scene.scene_id,
                person_id=UUID(person["person_id"]),
                confidence=person["confidence"],
                frame_count=1  # One frame sampled per scene
            )
            session.add(scene_person)

    session.commit()
```

5. Sidecar People Array (lines 380-418):
```python
for scene in scenes:
    # Query ScenePerson associations
    scene_people = session.query(ScenePerson).filter(
        ScenePerson.scene_id == scene.scene_id
    ).all()

    # Build people list
    people_list = []
    for sp in scene_people:
        person = session.query(FaceProfile).get(sp.person_id)
        people_list.append({
            "person_id": str(sp.person_id),
            "name": person.name,
            "confidence": sp.confidence,
            "frame_count": sp.frame_count
        })

    # Build sidecar with people
    sidecar = build_sidecar(..., people=people_list)
```

6. Updated build_sidecar() (line 661):
```python
def build_sidecar(..., people: List[Dict] = None, ...):
    sidecar = {
        ...,
        "people": people or [],  # Now populated with detected faces
        ...
    }
```

================================================================================
EXAMPLE SIDECAR WITH PEOPLE
================================================================================

{
  "video_id": "uuid",
  "scene_id": "uuid",
  "start_s": 0.0,
  "end_s": 5.2,
  "transcript": {...},
  "embeddings": {...},
  "vision_tags": {},
  "people": [
    {
      "person_id": "uuid",
      "name": "John Doe",
      "confidence": 0.85,
      "frame_count": 1
    },
    {
      "person_id": "uuid",
      "name": "Jane Smith",
      "confidence": 0.78,
      "frame_count": 1
    }
  ],
  "metadata": {...}
}

================================================================================
DATABASE SCHEMA
================================================================================

ScenePerson (association table):
- scene_id (FK to scenes.scene_id) - CASCADE DELETE
- person_id (FK to face_profiles.person_id) - CASCADE DELETE
- confidence (float) - Match confidence score 0-1
- frame_count (int) - Number of frames where person detected
- Composite primary key: (scene_id, person_id)

Relationships:
- Scene.people -> List[ScenePerson]
- FaceProfile.scene_associations -> List[ScenePerson]
- ScenePerson.scene -> Scene
- ScenePerson.person -> FaceProfile

================================================================================
FEATURE FLAGS & CONFIGURATION
================================================================================

Required Environment Variables:
- FEATURE_FACE_DETECTION=true (enable face detection in videos)
- FEATURE_FACE_ENROLLMENT=true (enable people photo upload, Phase 1)
- FACE_SIMILARITY_THRESHOLD=0.6 (cosine similarity threshold for matches)

Optional:
- FACE_MODEL_NAME=opencv/face_detection_yunet
- FACE_MODEL_FILE=face_detection_yunet_2023mar.onnx

Default Behavior (all flags false):
- No face detection during video processing
- People array in sidecars is always empty []
- No ScenePerson records created
- No performance impact

================================================================================
PERFORMANCE NOTES
================================================================================

Face Detection Per Scene:
- ~50-100ms for YuNet detection (320x320 input)
- ~5-10ms per enrolled profile for embedding comparison
- Negligible impact if FEATURE_FACE_DETECTION=false (early return)

Total Overhead (with 5 enrolled profiles):
- ~100-150ms per scene
- For 23-scene video: ~2-3 seconds total

Database Operations:
- ScenePerson bulk insert after all scenes committed
- Sidecar generation queries ScenePerson per scene (indexed)

================================================================================
PLACEHOLDER WARNING
================================================================================

Current face embedding extraction is a PLACEHOLDER:
- Uses simple average pooling for dimensionality reduction
- NOT suitable for production face recognition
- Replace with real AdaFace model for accurate matching

Location: lines 147-155 in detect_and_match_faces()
Also in: worker/tasks/face_processor.py (compute_face_embedding)

================================================================================
TESTING INSTRUCTIONS
================================================================================

1. Enable face detection:
   - Set FEATURE_FACE_DETECTION=true in .env.local
   - Set FEATURE_FACE_ENROLLMENT=true
   - Restart worker: docker compose restart worker

2. Enroll a person:
   - POST /people with name
   - POST /people/{person_id}/photos (get presigned URL)
   - Upload photo to presigned URL
   - POST /people/{person_id}/photos/complete (trigger embedding)
   - Wait for worker to process (check FaceProfile.adaface_vec not null)

3. Upload video with person's face:
   - POST /videos/upload
   - Worker will detect faces and create ScenePerson records
   - Check sidecars for people array

4. Verify:
   - Check database: SELECT * FROM scene_people;
   - Check sidecar: people array should contain detected person info
   - Check logs: "[worker] Detected X people" messages

================================================================================
ROLLBACK PLAN
================================================================================

If issues occur:
1. Set FEATURE_FACE_DETECTION=false (disables face detection)
2. Restart worker
3. System continues working without face detection
4. Existing ScenePerson records remain (no data loss)

To fully rollback:
- Revert worker/tasks/video_processor.py changes
- DELETE FROM scene_people; (if needed)
- Restart worker

================================================================================
NEXT STEPS
================================================================================

Phase 4: Semantic Vector Search (PENDING)
- Upgrade search from keyword to vector similarity
- Use pgvector ANN search on text_vec and image_vec
- Implement hybrid scoring (text + vision + people)
- Add vector indexes (IVFFLAT or HNSW)

Future Improvements:
- Replace placeholder embeddings with real AdaFace
- Add multi-frame face detection (sample multiple frames per scene)
- Add face bounding box storage (for UI highlighting)
- Add face tracking across scenes (same person detection)

================================================================================
STATUS
================================================================================

Phase 1: People Photo Upload ✅ COMPLETE
Phase 2: Scene-Level Sidecars ✅ COMPLETE + TESTED
Phase 3: Face Detection in Videos ✅ COMPLETE (needs real-world testing)
Phase 4: Semantic Vector Search - PENDING

System Status: Deployable with feature flags
Worker Status: Restarted, ready for testing

================================================================================
DEVLOG: Phase 2 Implementation + GPU Optimization
================================================================================
Date: 2025-11-11 20:40
Session: Phase 2 completion and GPU fixes
Video processed: 23 scenes with sidecars generated successfully

================================================================================
PHASE 2: SCENE-LEVEL SIDECAR GENERATION (COMPLETED)
================================================================================

Files Modified:
- worker/tasks/video_processor.py

Changes:
1. Added build_sidecar() function (lines 470-534)
   - Creates JSON metadata for each scene
   - Includes: video_id, scene_id, timing, transcript with segments,
     embedding metadata, vision_tags, people array, processing info

2. Added upload_sidecar() function (lines 537-568)
   - Serializes to UTF-8 JSON
   - Auto-creates sidecars bucket if needed
   - Uploads to MinIO

3. Pipeline integration (lines 195-231)
   - After scene commit, queries all scenes
   - Generates and uploads sidecar for each
   - Updates scenes.sidecar_key
   - Storage path: sidecars/{user_id}/{video_id}/{scene_id}.json

Example Sidecar:
{
  "video_id": "uuid",
  "scene_id": "uuid",
  "start_s": 0.0,
  "end_s": 1.418,
  "transcript": {"text": "...", "segments": [...], "language": "ko"},
  "embeddings": {
    "text": {"model": "BAAI/bge-m3", "dimensions": 1024, "has_embedding": true},
    "vision": {"model": "google/siglip-so400m-patch14-384", "dimensions": 1152, "has_embedding": true}
  },
  "vision_tags": {},
  "people": [],
  "metadata": {...}
}

Results:
✅ Test video processed: 23 scenes, all sidecars generated successfully
✅ Sidecars stored in MinIO under sidecars bucket
✅ Scene records updated with sidecar_key
✅ ~1KB per sidecar, ~10-50ms generation time per scene

================================================================================
GPU OPTIMIZATION FIXES
================================================================================

Problem:
- CPU usage 400%+ during video processing
- BGE-M3 and SigLIP not using GPU despite CUDA available
- Warning messages about slow processors

Root Cause:
- BGE-M3 FlagModel not configured to use GPU
- SigLIP processor using slow mode
- Only Whisper was using GPU correctly

Files Modified:
- worker/tasks/video_processor.py (lines 52-71)

Changes Made:

1. BGE-M3 GPU Support (lines 52-62):
```python
elif model_name == "bge-m3":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[worker] Loading BGE-M3 from HuggingFace on {device}")
    _models["bge-m3"] = FlagModel(
        "BAAI/bge-m3",
        query_instruction_for_retrieval="Represent this sentence for searching relevant passages:",
        use_fp16=True if device == "cuda" else False,  # FP16 on GPU for 2x speedup
        cache_dir="/app/models/.cache",
        devices=[device]  # Explicit device assignment
    )
```

2. SigLIP Fast Processor (lines 64-71):
```python
elif model_name == "siglip":
    model_path = os.getenv("VISION_MODEL_NAME", "google/siglip-so400m-patch14-384")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[worker] Loading SigLIP from {model_path} on {device}")
    processor = AutoProcessor.from_pretrained(model_path, use_fast=True)  # Fast processor
    model = AutoModel.from_pretrained(model_path)
    model = model.to(device)
    _models["siglip"] = {"model": model, "processor": processor, "device": device}
```

Expected Performance:
- CPU: 400% → 150-250% (only ffmpeg, cv2, PySceneDetect remain on CPU)
- GPU: 10-20% → 40-80% utilization
- Speed: 2-3x faster text embedding generation
- Warnings: Eliminated

Deployment:
- docker compose restart worker

GPU Status Verified:
- NVIDIA RTX 4060 Ti detected
- 7823MiB / 8188MiB VRAM used
- CUDA 12.6 available
- PyTorch CUDA: True

CPU-Only Operations (Expected/Normal):
- ffmpeg audio extraction
- PySceneDetect scene detection
- cv2.VideoCapture frame extraction
- MinIO upload/download (network I/O)
- PostgreSQL operations (database I/O)
- JSON serialization

================================================================================
TESTING & VERIFICATION
================================================================================

Test Video: 1eed31d9-154e-4f69-9347-cc96b1dcab9c
- User: 015d5356-37b4-4a21-a5b9-03c7c950cef8
- Scenes created: 23
- Sidecars generated: 23
- All sidecars uploaded successfully
- Sample verified: Korean transcript, embeddings present

Next Video Upload Will Show:
✅ "[worker] Loading BGE-M3 from HuggingFace on cuda"
✅ "[worker] Loading SigLIP from google/siglip-so400m-patch14-384 on cuda"
✅ No slow processor warnings
✅ Lower CPU usage
✅ Faster processing

================================================================================
STATUS
================================================================================

Phase 1: People Photo Upload ✅ COMPLETE
Phase 2: Scene-Level Sidecars ✅ COMPLETE + TESTED
Phase 3: Face Detection in Videos - PENDING
Phase 4: Semantic Vector Search - PENDING

System Status: Deployable, GPU-optimized, tested with real video
